{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeQLjGnJ2TQs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4iNP5D-2TQ3"
   },
   "outputs": [],
   "source": [
    "path_to_dataset=\"/content/NLP-Hamlet by William Shakespeare.TXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUhz_0vp2TRA"
   },
   "outputs": [],
   "source": [
    "text=open(path_to_dataset,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "r98G1BWL2TRH",
    "outputId": "c7a57a31-d634-4415-d1ab-42de8f5dac2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '~']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for the unique character in the dataset\n",
    "vocab=sorted(set(text))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKjWnDPH2TRN"
   },
   "outputs": [],
   "source": [
    "#Assigning the value to every unique character\n",
    "char_to_ind={char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uOblpjNH2TRT",
    "outputId": "61b3ea0f-ef17-4324-b4f7-118234aa524a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '#': 4,\n",
       " '$': 5,\n",
       " '%': 6,\n",
       " '&': 7,\n",
       " \"'\": 8,\n",
       " '(': 9,\n",
       " ')': 10,\n",
       " '*': 11,\n",
       " '+': 12,\n",
       " ',': 13,\n",
       " '-': 14,\n",
       " '.': 15,\n",
       " '/': 16,\n",
       " '0': 17,\n",
       " '1': 18,\n",
       " '2': 19,\n",
       " '3': 20,\n",
       " '4': 21,\n",
       " '5': 22,\n",
       " '6': 23,\n",
       " '7': 24,\n",
       " '8': 25,\n",
       " '9': 26,\n",
       " ':': 27,\n",
       " ';': 28,\n",
       " '<': 29,\n",
       " '=': 30,\n",
       " '>': 31,\n",
       " '?': 32,\n",
       " '@': 33,\n",
       " 'A': 34,\n",
       " 'B': 35,\n",
       " 'C': 36,\n",
       " 'D': 37,\n",
       " 'E': 38,\n",
       " 'F': 39,\n",
       " 'G': 40,\n",
       " 'H': 41,\n",
       " 'I': 42,\n",
       " 'J': 43,\n",
       " 'K': 44,\n",
       " 'L': 45,\n",
       " 'M': 46,\n",
       " 'N': 47,\n",
       " 'O': 48,\n",
       " 'P': 49,\n",
       " 'Q': 50,\n",
       " 'R': 51,\n",
       " 'S': 52,\n",
       " 'T': 53,\n",
       " 'U': 54,\n",
       " 'V': 55,\n",
       " 'W': 56,\n",
       " 'X': 57,\n",
       " 'Y': 58,\n",
       " 'Z': 59,\n",
       " '[': 60,\n",
       " ']': 61,\n",
       " '_': 62,\n",
       " 'a': 63,\n",
       " 'b': 64,\n",
       " 'c': 65,\n",
       " 'd': 66,\n",
       " 'e': 67,\n",
       " 'f': 68,\n",
       " 'g': 69,\n",
       " 'h': 70,\n",
       " 'i': 71,\n",
       " 'j': 72,\n",
       " 'k': 73,\n",
       " 'l': 74,\n",
       " 'm': 75,\n",
       " 'n': 76,\n",
       " 'o': 77,\n",
       " 'p': 78,\n",
       " 'q': 79,\n",
       " 'r': 80,\n",
       " 's': 81,\n",
       " 't': 82,\n",
       " 'u': 83,\n",
       " 'v': 84,\n",
       " 'w': 85,\n",
       " 'x': 86,\n",
       " 'y': 87,\n",
       " 'z': 88,\n",
       " '~': 89}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RLgoUgY02TRZ",
    "outputId": "58947e62-b092-45be-db37-1624145652d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=\n"
     ]
    }
   ],
   "source": [
    "ind_to_char=np.array(vocab)\n",
    "print(ind_to_char[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvrK0WFY2TRe"
   },
   "outputs": [],
   "source": [
    "#Encoding  the whole dataset according to the \n",
    "encoded_text=np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yr2s-1Ou2TRi",
    "outputId": "b3c74a4a-0978-4bba-9167-a4dd8c39b2f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, ..., 67, 15,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FNXkRYbQ2TRr",
    "outputId": "f660664b-3d6f-4675-e3a7-21b22ec17c68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179096,)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "XAZISzBv2TRw",
    "outputId": "5b696d22-2450-4e0c-895d-ba25c0a6b323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***The Project Gutenberg's Etext of Shakespeare's First Folio***\n",
      "*********************The Tragedie of Hamlet*********************\n",
      "\n",
      "\n",
      "*******************************************************************\n",
      "THIS EBOOK WAS ONE OF PROJECT GUTENBERG'S EARLY FILES PRODUCED AT A\n",
      "TIME WHEN PROOFING METHODS AND TOOLS WERE NOT WELL DEVELOPED. THERE\n",
      "IS AN IMPROVED EDITION OF THIS TITLE WHICH MAY BE VIEWED AS EBOOK\n",
      "(#100) at https://www.gutenberg.org/ebooks/100\n",
      "*******************************************************************\n",
      "\n",
      "\n",
      "This is our 3rd edition of most of these plays.  See the index.\n",
      "\n",
      "\n",
      "Copyright laws are changing all over the world, be sure to check\n",
      "the copyright laws for your country before posting these files!!\n",
      "\n",
      "Please take a look at the important information in this header.\n",
      "We encourage you to keep this file on your own disk, keeping an\n",
      "electronic path open for the next readers.  Do not remove this.\n",
      "\n",
      "\n",
      "**Welcome To The World of Free Plain Vanilla Electronic Texts**\n",
      "\n",
      "**Etexts Readable By Both\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "id": "o9j6K0S32TR2",
    "outputId": "388bcf8b-37b7-4bd3-f523-f6d9c42e2f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 53 70 67  1 49 80 77 72 67 65 82  1 40 83 82 67 76 64 67 80 69\n",
      "  8 81  1 38 82 67 86 82  1 77 68  1 52 70 63 73 67 81 78 67 63 80 67  8\n",
      " 81  1 39 71 80 81 82  1 39 77 74 71 77 11 11 11  0 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 53 70 67  1 53 80 63 69 67 66\n",
      " 71 67  1 77 68  1 41 63 75 74 67 82 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11  0  0  0 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11  0 53 41 42 52  1 38 35 48 48 44  1 56 34 52  1 48\n",
      " 47 38  1 48 39  1 49 51 48 43 38 36 53  1 40 54 53 38 47 35 38 51 40  8\n",
      " 52  1 38 34 51 45 58  1 39 42 45 38 52  1 49 51 48 37 54 36 38 37  1 34\n",
      " 53  1 34  0 53 42 46 38  1 56 41 38 47  1 49 51 48 48 39 42 47 40  1 46\n",
      " 38 53 41 48 37 52  1 34 47 37  1 53 48 48 45 52  1 56 38 51 38  1 47 48\n",
      " 53  1 56 38 45 45  1 37 38 55 38 45 48 49 38 37 15  1 53 41 38 51 38  0\n",
      " 42 52  1 34 47  1 42 46 49 51 48 55 38 37  1 38 37 42 53 42 48 47  1 48\n",
      " 39  1 53 41 42 52  1 53 42 53 45 38  1 56 41 42 36 41  1 46 34 58  1 35\n",
      " 38  1 55 42 38 56 38 37  1 34 52  1 38 35 48 48 44  0  9  4 18 17 17 10\n",
      "  1 63 82  1 70 82 82 78 81 27 16 16 85 85 85 15 69 83 82 67 76 64 67 80\n",
      " 69 15 77 80 69 16 67 64 77 77 73 81 16 18 17 17  0 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11  0  0  0 53 70 71 81  1 71 81  1 77\n",
      " 83 80  1 20 80 66  1 67 66 71 82 71 77 76  1 77 68  1 75 77 81 82  1 77\n",
      " 68  1 82 70 67 81 67  1 78 74 63 87 81 15  1  1 52 67 67  1 82 70 67  1\n",
      " 71 76 66 67 86 15  0  0  0 36 77 78 87 80 71 69 70 82  1 74 63 85 81  1\n",
      " 63 80 67  1 65 70 63 76 69 71 76 69  1 63 74 74  1 77 84 67 80  1 82 70\n",
      " 67  1 85 77 80 74 66 13  1 64 67  1 81 83 80 67  1 82 77  1 65 70 67 65\n",
      " 73  0 82 70 67  1 65 77 78 87 80 71 69 70 82  1 74 63 85 81  1 68 77 80\n",
      "  1 87 77 83 80  1 65 77 83 76 82 80 87  1 64 67 68 77 80 67  1 78 77 81\n",
      " 82 71 76 69  1 82 70 67 81 67  1 68 71 74 67 81  2  2  0  0 49 74 67 63\n",
      " 81 67  1 82 63 73 67  1 63  1 74 77 77 73  1 63 82  1 82 70 67  1 71 75\n",
      " 78 77 80 82 63 76 82  1 71 76 68 77 80 75 63 82 71 77 76  1 71 76  1 82\n",
      " 70 71 81  1 70 67 63 66 67 80 15  0 56 67  1 67 76 65 77 83 80 63 69 67\n",
      "  1 87 77 83  1 82 77  1 73 67 67 78  1 82 70 71 81  1 68 71 74 67  1 77\n",
      " 76  1 87 77 83 80  1 77 85 76  1 66 71 81 73 13  1 73 67 67 78 71 76 69\n",
      "  1 63 76  0 67 74 67 65 82 80 77 76 71 65  1 78 63 82 70  1 77 78 67 76\n",
      "  1 68 77 80  1 82 70 67  1 76 67 86 82  1 80 67 63 66 67 80 81 15  1  1\n",
      " 37 77  1 76 77 82  1 80 67 75 77 84 67  1 82 70 71 81 15  0  0  0 11 11\n",
      " 56 67 74 65 77 75 67  1 53 77  1 53 70 67  1 56 77 80 74 66  1 77 68  1\n",
      " 39 80 67 67  1 49 74 63 71 76  1 55 63 76 71 74 74 63  1 38 74 67 65 82\n",
      " 80 77 76 71 65  1 53 67 86 82 81 11 11  0  0 11 11 38 82 67 86 82 81  1\n",
      " 51 67 63 66 63 64 74 67  1 35 87  1 35 77 82 70]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "61ETBqJd2TR6",
    "outputId": "389dd1ab-733f-4c76-ab20-43fbf2268569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not to crack the winde of the poore Phrase,\n",
      "Roaming it thus, you'l tender me a foole\n",
      "\n",
      "   Ophe. My Lord, he hath importun'd me with loue,\n",
      "In honourable fashion\n",
      "\n",
      "   Polon. I, fashion you may call it, go too, go too\n",
      "\n",
      "   Ophe. And hath giuen countenance to his speech,\n",
      "My Lord, with all the vowes of Heauen\n",
      "\n",
      "   Polon. I, Springes to catch Woodcocks. I doe know\n",
      "When the Bloud burnes, how Prodigall the Soule\n",
      "Giues the tongue vowes: these blazes, Daughter,\n",
      "Giuing more light then heate; extinct in both,\n",
      "Euen in their promise, as it is a making;\n",
      "You must not take for fire. For this time Daughter,\n",
      "Be somewhat scanter of your Maiden presence;\n",
      "Set your entreatments at a higher rate,\n",
      "Then a command to parley. For Lord Hamlet,\n",
      "Beleeue so much in him, that he is young,\n",
      "And with a larger tether may he walke,\n",
      "Then may be giuen you. In few, Ophelia,\n",
      "Doe not beleeue his vowes; for they are Broakers,\n",
      "Not of the eye, which their Inuestments show:\n",
      "But meere implorators of vnholy Sutes,\n",
      "Breathing like sanctified and pious bonds,\n",
      "The better to beguile. This is for all:\n",
      "I would not, in plaine tearmes, from this time forth,\n",
      "Haue you so slander any moment leisure,\n",
      "As to giue words or talke with the Lord Hamlet:\n",
      "Looke too't, I charge you; come your wayes\n",
      "\n",
      "   Ophe. I shall obey my Lord.\n",
      "\n",
      "Exeunt.\n",
      "\n",
      "Enter Hamlet, Horatio, Marcellus.\n",
      "\n",
      "  Ham. The Ayre bites shrewdly: is it very cold?\n",
      "  Hor. It is a nipping and an eager ayre\n",
      "\n",
      "   Ham. What hower now?\n",
      "  Hor. I thinke it lacks of twelue\n",
      "\n",
      "   Mar. No, it is strooke\n",
      "\n",
      "   Hor. Indeed I heard it not: then it drawes neere the season,\n",
      "Wherein the Spirit held his wont to walke.\n",
      "What does this meane my Lord?\n",
      "  Ham. The King doth wake to night, and takes his rouse,\n",
      "Keepes wassels and the swaggering vpspring reeles,\n",
      "And as he dreines his draughts of Renish downe,\n",
      "The kettle Drum and Trumpet thus bray out\n",
      "The triumph of his Pledge\n",
      "\n",
      "   Horat. Is it a custome?\n",
      "  Ham. I marry ist;\n",
      "And to my mind, though I am natiue heere,\n",
      "And to the manner borne: It is a Custome\n",
      "More honour'd in the breach, then the obseruance.\n",
      "Enter Ghost.\n",
      "\n",
      "  Hor. Looke my Lord, it comes\n",
      "\n",
      "   Ham. Angels and Ministers of Grace defend vs:\n",
      "Be thou a Spirit of health, or Goblin damn'd,\n",
      "Bring with thee ayres from Heauen, or blasts from Hell,\n",
      "Be thy euents wicked or charitable,\n",
      "Thou com'st in such a questionable shape\n",
      "That I will speake to thee. Ile call thee Hamlet,\n",
      "King, Father, Royall Dane: Oh, oh, answer me,\n",
      "Let me not burst in Ignorance; but tell\n",
      "Why thy Canoniz'd bones Hearsed in death,\n",
      "Haue burst their cerments, why the Sepulcher\n",
      "Wherein we saw thee quietly enurn'd,\n",
      "Hath op'd his ponderous and Marble iawes,\n",
      "To cast thee vp againe? What may this meane?\n",
      "That thou dead Coarse againe in compleat steele,\n",
      "Reuisits thus the glimpses of the Moone,\n",
      "Making Night hidious? And we fooles of Nature,\n",
      "So horridly to shake our disposition,\n",
      "With thoughts beyond thee; reaches of our Soules,\n",
      "Say, why is this? wherefore? what should we doe?\n",
      "\n",
      "Ghost beckens Hamlet.\n",
      "\n",
      "  Hor. It beckons you to goe away with it,\n",
      "As if it some impartment did desire\n",
      "To you alone\n",
      "\n",
      "   Mar. Looke with what courteous action\n",
      "It wafts you to a more remoued ground:\n",
      "But doe not goe with it\n",
      "\n",
      "   Hor. No, by no meanes\n",
      "\n",
      "   Ham. It will not speake: then will I follow it\n",
      "\n",
      "   Hor. Doe not my Lord\n",
      "\n",
      "   Ham. Why, what should be the feare?\n",
      "I doe not set my life at a pins fee;\n",
      "And for my Soule, what can it doe to that?\n",
      "Being a thing immortall as it selfe:\n",
      "It waues me forth againe; Ile follow it\n",
      "\n",
      "   Hor. What if it tempt you toward the Floud my Lord?\n",
      "Or to the dreadfull Sonnet of the Cliffe,\n",
      "That beetles o're his base into the Sea,\n",
      "And there assumes some other horrible forme,\n",
      "Which might depriue your Soueraignty of Reason,\n",
      "And draw you into madnesse thinke of it?\n",
      "  Ham. It wafts me still: goe on, Ile follow thee\n",
      "\n",
      "   Mar. You shall not goe my Lord\n",
      "\n",
      "   Ham. Hold off your hand\n",
      "\n",
      "   Hor. Be rul'd, you shall not goe\n",
      "\n",
      "   Ham. My fate cries out,\n",
      "And makes each petty Artire in this body,\n",
      "As hardy as the Nemian Lions nerue:\n",
      "Still am I cal'd? Vnhand me Gentlemen:\n",
      "By Heau'n, Ile make a Ghost of him that lets me:\n",
      "I say away, goe on, Ile follow thee.\n",
      "\n",
      "Exeunt. Ghost & Hamlet.\n",
      "\n",
      "  Hor. He waxes desperate with imagination\n",
      "\n",
      "   Mar. Let's follow; 'tis not fit thus to obey him\n",
      "\n",
      "   Hor. Haue after, to what issue will this come?\n",
      "  Mar. Something is rotten in the State of Denmarke\n",
      "\n",
      "   Hor. Heauen will direct it\n",
      "\n",
      "   Mar. Nay, let's follow him.\n",
      "\n",
      "Exeunt.\n",
      "\n",
      "Enter Ghost and Hamlet.\n",
      "\n",
      "  Ham. Where wilt thou lead me? speak; Ile go no further\n",
      "\n",
      "   Gho. Marke me\n",
      "\n",
      "   Ham. I will\n",
      "\n",
      "   Gho. My hower is almost come,\n",
      "When I to sulphurous and tormenting Flames\n",
      "Must render vp my selfe\n",
      "\n",
      "   Ham. Alas poore Ghost\n",
      "\n",
      "   Gho. Pitty me not, but lend thy serious hearing\n",
      "To what I shall vnfold\n",
      "\n",
      "   Ham. Speake, I am bound to heare\n",
      "\n",
      "   Gho. So art thou to reuenge, when thou shalt heare\n",
      "\n",
      "   Ham. What?\n",
      "  Gho. I am thy Fathers Spirit,\n",
      "Doom'd for a certaine terme to walke the night;\n",
      "And for the day confin'd to fast in Fiers,\n",
      "Till the foule crimes done in my dayes of Nature\n",
      "Are burnt and purg'd away? But that I am forbid\n",
      "To tell the secrets of my Prison-House;\n",
      "I could a Tale vnfold, whose lightest word\n",
      "Would harrow vp thy soule, freeze thy young blood,\n",
      "Make thy two eyes like Starres, start from their Spheres,\n",
      "Thy knotty and combined lockes to part,\n",
      "And each particular haire to stand an end,\n",
      "Like Quilles vpon the fretfull Porpentine:\n",
      "But this eternall blason must not be\n",
      "To eares of flesh and bloud; list Hamlet, oh list,\n",
      "If thou didst euer thy deare Father loue\n",
      "\n",
      "   Ham. Oh Heauen!\n",
      "  Gho. Reuenge his foule and most vnnaturall Murther\n",
      "\n",
      "   Ham. Murther?\n",
      "  Ghost. Murther most foule, as in the best it is;\n",
      "But this most foule, strange, and vnnaturall\n",
      "\n",
      "   Ham. Hast, hast me to know it,\n",
      "That with wings as swift\n",
      "As meditation, or the thoughts of Loue,\n",
      "May sweepe to my Reuenge\n",
      "\n",
      "   Ghost. I finde thee apt,\n",
      "And duller should'st thou be then the fat weede\n",
      "That rots it selfe in ease, on Lethe Wharfe,\n",
      "Would'st thou not stirre in this. Now Hamlet heare:\n",
      "It's giuen out, that sleeping in mine Orchard,\n",
      "A Serpent stung me: so the whole eare of Denmarke,\n",
      "Is by a forged processe of my death\n",
      "Rankly abus'd: But know thou Noble youth,\n",
      "The Serpent that did sting thy Fathers life,\n",
      "Now weares his Crowne\n",
      "\n",
      "   Ham. O my Propheticke soule: mine Vncle?\n",
      "  Ghost. I that incestuous, that adulterate Beast\n",
      "With witchcraft of his wits, hath Traitorous guifts.\n",
      "Oh wicked Wit, and Gifts, that haue the power\n",
      "So to seduce? Won to this shamefull Lust\n",
      "The will of my most seeming vertuous Queene:\n",
      "Oh Hamlet, what a falling off was there,\n",
      "From me, whose loue was of that dignity,\n",
      "That it went hand in hand, euen with the Vow\n",
      "I made to her in Marriage; and to decline\n",
      "Vpon a wretch, whose Naturall gifts were poore\n",
      "To those of mine. But Vertue, as it neuer wil be moued,\n",
      "Though Lewdnesse court it in a shape of Heauen:\n",
      "So Lust, though to a radiant Angell link'd,\n",
      "Will sate it selfe in a Celestiall bed, & prey on Garbage.\n",
      "But soft, me thinkes I sent the Mornings Ayre;\n",
      "Briefe let me be: Sleeping within mine Orchard,\n",
      "My custome alwayes in the afternoone;\n",
      "Vpon my secure hower thy Vncle stole\n",
      "With iuyce of cursed Hebenon in a Violl,\n",
      "And in the Porches of mine eares did poure\n",
      "The leaperous Distilment; whose effect\n",
      "Holds such an enmity with bloud of Man,\n",
      "That swift as Quick-siluer, it courses through\n",
      "The naturall Gates and Allies of the body;\n",
      "And with a sodaine vigour it doth posset\n",
      "And curd, like Aygre droppings into Milke,\n",
      "The thin and wholsome blood: so did it mine;\n",
      "And a most instant Tetter bak'd about,\n",
      "Most Lazar-like, with vile and loathsome crust,\n",
      "All my smooth Body.\n",
      "Thus was I, sleeping, by a Brothers hand,\n",
      "Of Life, of Crowne, and Queene at once dispatcht;\n",
      "Cut off euen in the Blossomes of my Sinne,\n",
      "Vnhouzzled, disappointed, vnnaneld,\n",
      "No reckoning made, but sent to my account\n",
      "With all my imperfections on my head;\n",
      "Oh horrible Oh horrible, most horrible:\n",
      "If thou hast nature in thee beare it not;\n",
      "Let not the Royall Bed of Denmarke be\n",
      "A Couch for Luxury and damned Incest.\n",
      "But howsoeuer thou pursuest this Act,\n",
      "Taint not thy mind; nor let thy Soule contriue\n",
      "Against thy Mother ought; leaue her to heauen,\n",
      "And to those Thornes that in her bosome lodge,\n",
      "To pricke and sting her. Fare thee well at once;\n",
      "The Glow-worme showes the Matine to be neere,\n",
      "And gins to pale his vneffectuall Fire:\n",
      "Adue, adue, Hamlet: remember me.\n",
      "Enter.\n",
      "\n",
      "  Ham. Oh all you host of Heauen! Oh Earth; what els?\n",
      "And shall I couple Hell? Oh fie: hold my heart;\n",
      "And you my sinnewes, grow not instant Old;\n",
      "But beare me stiffely vp: Remember thee?\n",
      "I, thou poore Ghost, while memory holds a seate\n",
      "In this distracted Globe: Remember thee?\n",
      "Yea, from the Table of my Memory,\n",
      "Ile wipe away all triuiall fond Records,\n",
      "All sawes of Bookes, all formes, all presures past,\n",
      "That youth and obseruation coppied there;\n",
      "And thy Commandment all alone shall liue\n",
      "Within the Booke and Volume of my Braine,\n",
      "Vnmixt with baser matter; yes yes, by Heauen:\n",
      "Oh most pernicious woman!\n",
      "Oh Villaine, Villaine, smiling damned Villaine!\n",
      "My Tables, my Tables; meet it is I set it downe,\n",
      "That one may smile, and smile and be a Villaine;\n",
      "At least I'm sure it may be so in Denmarke;\n",
      "So Vnckle there you are: now to my word;\n",
      "It is; Adue, Adue, Remember me: I haue sworn't\n",
      "\n",
      "   Hor. & Mar. within. My Lord, my Lord.\n",
      "Enter Horatio and Marcellus.\n",
      "\n",
      "  Mar. Lord Hamlet\n",
      "\n",
      "   Hor. Heauen secure him\n",
      "\n",
      "   Mar. So be it\n",
      "\n",
      "   Hor. Illo, ho, ho, my Lord\n",
      "\n",
      "   Ham. Hillo, ho, ho, boy; come bird, come\n",
      "\n",
      "   Mar. How ist my Noble Lord?\n",
      "  Hor. What newes, my Lord?\n",
      "  Ham. Oh wonderfull!\n",
      "  Hor. Good my Lord tell it\n",
      "\n",
      "   Ham. No you'l reueale it\n",
      "\n",
      "   Hor. Not I, my Lord, by Heauen\n",
      "\n",
      "   Mar. Nor I, my Lord\n",
      "\n",
      "   Ham. How say you then, would heart of man once think it?\n",
      "But you'l be secret?\n",
      "  Both. I, by Heau'n, my Lord\n",
      "\n",
      "   Ham. There's nere a villaine dwelling in all Denmarke\n",
      "But hee's an arrant knaue\n",
      "\n",
      "   Hor. There needs no Ghost my Lord, come from the\n",
      "Graue, to tell vs this\n",
      "\n",
      "   Ham. Why right, you are i'th' right;\n",
      "And so, without more circumstance at all,\n",
      "I \n"
     ]
    }
   ],
   "source": [
    "print(text[40000:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vjLgeori2TR-",
    "outputId": "02f32efb-bded-48af-86bd-dd2515a82d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"\"\"And shall I couple Hell? Oh fie: hold my heart;\n",
    "And you my sinnewes, grow not instant Old;\n",
    "But beare me stiffely vp: Remember thee?\"\"\"\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQV2gmLL2TSB"
   },
   "outputs": [],
   "source": [
    "seq_length=130\n",
    "total_num_seq=len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "21NEHvi_2TSG",
    "outputId": "f62cf74a-2077-45f8-f5f1-7f767a0e83de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMX_Wcet2TSJ"
   },
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybzcDrvH2TSN"
   },
   "outputs": [],
   "source": [
    "# for i in char_dataset.take(500):\n",
    "#     print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yd7THfzf2TSQ"
   },
   "outputs": [],
   "source": [
    "sequence=char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUt1-5UJ2TST"
   },
   "outputs": [],
   "source": [
    "def create_seq_target(seq):\n",
    "    input_text=seq[:-1]\n",
    "    target_text=seq[1:]\n",
    "    \n",
    "    return input_text,target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROVsw5XH2TSV"
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "dataset=sequence.map(create_seq_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNXXIa0y2TSa"
   },
   "outputs": [],
   "source": [
    "batch_size=126\n",
    "buffer_size=1000\n",
    "#Shuffled Dateset\n",
    "dataset=dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oOqk-qWL2TSe",
    "outputId": "c91f9e89-6f8e-4d36-db2a-3f11ba438cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((126, 130), (126, 130)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZBKpk2F2TSh"
   },
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LGWtS5eZ2TSk",
    "outputId": "c3b8e274-9330-4ddb-cd89-cf3b4126129b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4qF3io02TSo",
    "outputId": "60f64619-f415-43ff-c3c5-8db62c076ff6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "embed_dim=70\n",
    "rr_neuron=1024\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "#Custom Loss Function\n",
    "def sparse(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4jCVeQH2TSq"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Embedding,GRU\n",
    "def create_model(vocab_size,embed_dim,rr_neuron,batch_size):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
    "    model.add(GRU(rr_neuron,return_sequences=True, stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam',loss=sparse)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "vZkdhHyH2TSu",
    "outputId": "22de8426-a7ff-44fa-d34b-19473d7e96ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (126, None, 70)           6300      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (126, None, 1024)         3366912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (126, None, 90)           92250     \n",
      "=================================================================\n",
      "Total params: 3,465,462\n",
      "Trainable params: 3,465,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title Default title text\n",
    "model=create_model(vocab_size=vocab_size, embed_dim=embed_dim, rr_neuron=rr_neuron,batch_size=batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "1Bk3eA-LMiRy",
    "outputId": "cd219643-6d8c-4689-ca91-f6e196f1a51d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['h', 'P', 'G', '.', 'h', 'M', 'j', '&', 'Y', '<', '(', '\\n', 'i',\n",
       "       'm', ';', 'y', 'H', 'Z', '6', '!', '9', '6', '4', 'E', 't', 'w',\n",
       "       '>', '>', 'x', ' ', 'n', '&', '<', '7', '8', 'g', '.', '?', 'X',\n",
       "       '6', '-', 'b', '[', '0', '-', ':', '$', 'o', 'e', 'v', 'Q', '7',\n",
       "       '@', 'K', 'E', 'w', 'b', '$', '+', '/', '!', 'k', 'h', '@', 't',\n",
       "       '$', '!', '7', 'H', 'c', 'Y', 'R', 'F', 'q', '#', 't', 'q', 't',\n",
       "       '\\n', 'F', '8', '+', 'G', 'T', 'P', '5', 'r', 'o', 'D', 'Z', 'X',\n",
       "       'v', 'l', '~', '?', '*', 'E', '>', 'U', '!', 'X', 'f', 'T', '/',\n",
       "       'S', 'x', ';', 'w', 'w', 'T', ']', '\"', '\\n', 'f', 'n', '_', '3',\n",
       "       'j', 'R', ' ', 'T', 'k', '[', 'y', '~', 'y', '.', 'w', 'M', '<'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Model Creation before training\n",
    "for input_example,target_example in dataset.take(1):\n",
    "  target_example=model(input_example)\n",
    "  \n",
    "sample_indices=tf.random.categorical(target_example[0],num_samples=1)\n",
    "sample_indices=tf.squeeze(sample_indices,axis=-1).numpy()\n",
    "ind_to_char[sample_indices]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1B3x7MXy2TSx",
    "outputId": "2ab4c4f1-ae09-4b0c-83a2-95c81c656a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 4.6110\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 85s 8s/step - loss: 3.9733\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 85s 9s/step - loss: 3.3363\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 85s 9s/step - loss: 3.1946\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 85s 9s/step - loss: 3.1450\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 84s 8s/step - loss: 3.1148\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 3.0248\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.9057\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 84s 8s/step - loss: 2.7775\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.6692\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.5902\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.5267\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 84s 8s/step - loss: 2.4767\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.4410\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.4049\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 81s 8s/step - loss: 2.3747\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 81s 8s/step - loss: 2.3420\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.3162\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.2900\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.2649\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 86s 9s/step - loss: 2.2416\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 86s 9s/step - loss: 2.2164\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 87s 9s/step - loss: 2.1914\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 85s 9s/step - loss: 2.1668\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.1426\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.1215\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.0965\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.0759\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 83s 8s/step - loss: 2.0532\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 82s 8s/step - loss: 2.0342\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "model.fit(dataset,epochs=epochs)\n",
    "#Saving the model\n",
    "model.save('Text_geneartor.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4iK0jwGEMtU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\"\"\"\n",
    "You can load the trained model by invoking the comments below\n",
    "\n",
    "\"\"\"\n",
    "# model=create_model(vocab_size=vocab_size, embed_dim=embed_dim, rr_neuron=rr_neuron,batch_size=1)\n",
    "# model.load_weights('/content/Text_geneartor.h5')\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0AZ_-ca2TS0"
   },
   "outputs": [],
   "source": [
    "#Text Generator function to generate the random text\n",
    "def generate_text(model,start_text,gen_size=500,temp=1.0):\n",
    "  num_generate=gen_size\n",
    "  input_val=[char_to_ind[s] for s in start_text]\n",
    "  #Converting the input to the desired shape to feed the model\n",
    "  input_val=tf.expand_dims(input_val,0)\n",
    "\n",
    "  text_generated=[]\n",
    "  temprature=temp\n",
    "\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "    predictions=model(input_val)\n",
    "    predictions=tf.squeeze(predictions,0)\n",
    "    predictions=predictions/temprature\n",
    "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    input_val=tf.expand_dims([predicted_id],0)\n",
    "\n",
    "    text_generated.append(ind_to_char[predicted_id])\n",
    "    # print(text_generated)\n",
    "\n",
    "  return(start_text + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "Ue7rtATu2TS2",
    "outputId": "f628fb09-f267-429d-fb39-f2d76f71800e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAMLETqurge.\n",
      "Hay Wis will ald he the Mont, Nowin,\n",
      "Tho Clake Corfalle for ay Cord,\n",
      "Brke your wornt wath: Buthis you'd ar wathere the Quewers\n",
      "\n",
      "   Hor. Not sile wo Pale afawion me ofrte bafenn\n",
      "  por. King Is at no\n",
      "Snowend vndainges ss yeu wroung;\n",
      "Hertor, I when Nome-with ofe, the spulldingeran sely,\n",
      "And puieag thol now. Ho hal whe Gusteng. yit sopileres, ama soert, and you framf be? A Haml corse:\n",
      "Yot this a forte, thit houl Dame to\n",
      "\n",
      "   Col. Whet ouss ist rest?\n",
      "  Haml. Vr South your frothorgais his wers,\n",
      "The Praimer tot ou nolauth thele hin,\n",
      "Whow a Nonbitstee-hipt. the this: is the Pyease\n",
      "\n",
      "   Ham. there vpradnes\n",
      " lo Tondine sfeare minh hellow? ' Of ond now aedre:\n",
      "Ardine of, 'sthelime you wiur anf't axt it\n",
      "the; I her ate shand oferstser afd the eirel madecus now re beee dore\n",
      "\n",
      "  a gyoods. Getirus on wigh, Bul co rasll mend of?\n",
      "The Cawine and Grickens to lo\n",
      "Lou bot I he ivpreno reend inoued\n",
      "o pur shit so leake rim of Polyaur.\n",
      "\n",
      "Thy Queaiw boy co kuene seeren is death, Ant and ince Pore,\n",
      "Thad hemand \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"HAMLET\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29CaorjF2TS5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3O71qeh2TS7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jm-8C6I52TS_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
